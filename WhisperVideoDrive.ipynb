{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/torstenek/Whisper/blob/main/WhisperVideoDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above ðŸ‘†\n",
        "\n",
        "#ðŸ“¼ OpenAI Whisper + Google Drive Video Transcription\n",
        "\n",
        "ðŸ“º Getting started video: https://youtu.be/YGpYinji7II\n",
        "\n",
        "###This application will extract audio from all the video files in a Google Drive folder and create a high-quality transcription with OpenAI's Whisper automatic speech recognition system.\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperVideo folder and three subfolders (ProcessedVideo, AudioFiles and TextFiles.)\n",
        "3. When you run the application it will search for all the video files (.mp4, .mov, mkv and .avi) in your WhisperVideo folder, transcribe them and then move the file to WhisperVideo/ProcessedVideo and save the transcripts to WhisperVideo/TextFiles. It will also add a copy of the new audio file to WhisperVideo/AudioFiles\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ],
      "metadata": {
        "id": "oSzWV5We2jx0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TBOLg7X3mztt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Load the code libraries"
      ],
      "metadata": {
        "id": "pFx0mfr031aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install git+https://github.com/linto-ai/whisper-timestamped\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb\n",
        "\n",
        "import whisper\n",
        "# import whisper_timestamped as whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "# model = whisper.load_model(\"base.en\")  \n",
        "model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "id": "PomTPiCR5ihc",
        "outputId": "dea8c773-a8d0-4725-e3f1-613beb7df166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-w1tv3pb_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-w1tv3pb_\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.16.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.6.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.28.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.22.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (15.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (63.4.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/linto-ai/whisper-timestamped\n",
            "  Cloning https://github.com/linto-ai/whisper-timestamped to /tmp/pip-req-build-7e_f1xhv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/linto-ai/whisper-timestamped /tmp/pip-req-build-7e_f1xhv\n",
            "  Resolved https://github.com/linto-ai/whisper-timestamped to commit f5b6fb9f197649728d933d9d20929474828e67a1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (from whisper-timestamped==1.12.4) (0.29.33)\n",
            "Requirement already satisfied: dtw-python in /usr/local/lib/python3.9/dist-packages (from whisper-timestamped==1.12.4) (1.3.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.9/dist-packages (from whisper-timestamped==1.12.4) (1.14.1)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.9/dist-packages (from whisper-timestamped==1.12.4) (20230314)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (from whisper-timestamped==1.12.4) (0.13.1+cu116)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.9/dist-packages (from dtw-python->whisper-timestamped==1.12.4) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from dtw-python->whisper-timestamped==1.12.4) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime->whisper-timestamped==1.12.4) (23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from onnxruntime->whisper-timestamped==1.12.4) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime->whisper-timestamped==1.12.4) (23.3.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime->whisper-timestamped==1.12.4) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime->whisper-timestamped==1.12.4) (1.7.1)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (0.2.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (0.56.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (9.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (1.13.1+cu116)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper->whisper-timestamped==1.12.4) (2.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper->whisper-timestamped==1.12.4) (0.16.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (2.28.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.4) (3.9.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.4) (3.22.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper->whisper-timestamped==1.12.4) (15.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper->whisper-timestamped==1.12.4) (4.5.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime->whisper-timestamped==1.12.4) (10.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper->whisper-timestamped==1.12.4) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper->whisper-timestamped==1.12.4) (63.4.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime->whisper-timestamped==1.12.4) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper->whisper-timestamped==1.12.4) (1.26.15)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.43.0->librosa) (63.4.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.28.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (3.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Give the application permission to mount the drive and create the folders"
      ],
      "metadata": {
        "id": "JIjETRxb5nuE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxWvhDHzmspd",
        "outputId": "8460d7dc-9380-45b5-c3d7-34b82075d112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Create the Drive folders\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# This will create the WhisperVideo files if they don't exist.\n",
        "folders =  [\"WhisperVideo/\", \"WhisperVideo/ProcessedVideo/\", \"WhisperVideo/TextFiles/\", \"WhisperVideo/AudioFiles/\", \"WhisperVideo/JsonFiles/\"]\n",
        "for folder in folders:\n",
        "  path = \"/content/drive/MyDrive/\" + folder\n",
        "  if not os.path.exists(path): # Create the folder if it does not exist\n",
        "    os.mkdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file data.json into a Python dictionary\n",
        "\n",
        "import json\n",
        "\n",
        "# Function to read a JSON file and return its content as a Python dictionary\n",
        "def read_json_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def find_end_of_sentence(segmentText):\n",
        "    print(segmentText)\n",
        "    # find the end of the sentence\n",
        "    # if there is a period, then the end of the sentence is the period\n",
        "    # if there is a question mark, then the end of the sentence is the question mark\n",
        "    # if there is an exclamation point, then the end of the sentence is the exclamation point\n",
        "    # if there is no period, question mark, or exclamation point, then the end of the sentence is the end of the string\n",
        "    # return the end of the sentence\n",
        "    end_of_sentence = -1\n",
        "    if \".\" in segmentText:\n",
        "        end_of_sentence = segmentText.find(\".\")\n",
        "    elif \"?\" in segmentText:\n",
        "        end_of_sentence = segmentText.find(\"?\")\n",
        "    elif \"!\" in segmentText:\n",
        "        end_of_sentence = segmentText.find(\"!\")\n",
        "    return end_of_sentence\n",
        "\n",
        "# Function to determine if the segment is an incomplete sentence.\n",
        "# If the segmentText does not contain a period, question mark, or exclamation point,\n",
        "# then the segment is an incomplete sentence.\n",
        "def is_incomplete_sentence(segmentText):\n",
        "    end_of_sentence = find_end_of_sentence(segmentText)\n",
        "    return True if end_of_sentence == -1 else False\n",
        "\n",
        "\n",
        "# Transcribe traverses the segmentsArray starting from segmentIndex and forwards to find the\n",
        "# end of the next complete sentence.\n",
        "\n",
        "def transcribe(accumulatedSentenceStart, accumulatedSentenceText, segmentIndex, segmentsArray):\n",
        "    # We are at the end of the segmentsArray. Return.\n",
        "    if segmentIndex >= len(segmentsArray):\n",
        "        return\n",
        "    currentSegment = segmentsArray[segmentIndex]\n",
        "    currentSegmentText = currentSegment.get(\"text\")\n",
        "    thisAccumulatedSentenceText = \"\"\n",
        "    thisStartTimeStamp = currentSegment.get(\"start\")\n",
        "\n",
        "    # if previousSegment is None: then we set thisStartTimeStamp to the start time of the current segment\n",
        "    # else we set thisStartTimeStamp to the end time of the previous segment\n",
        "    if accumulatedSentenceStart is not None:\n",
        "        thisStartTimeStamp = accumulatedSentenceStart\n",
        "\n",
        "    if accumulatedSentenceText is not None:\n",
        "        thisSentenceText = accumulatedSentenceText\n",
        "\n",
        "    # If the segment is an incomplete sentence, then append the segmentText to the sentence\n",
        "    # and call transcribe again with the next segment.\n",
        "    if is_incomplete_sentence(currentSegmentText):\n",
        "        newSentenceAccumulatedText = thisAccumulatedSentenceText + currentSegmentText\n",
        "        transcribe(accumulatedSentenceStart, newSentenceAccumulatedText, segmentIndex + 1, segmentsArray)\n",
        "    else:\n",
        "        endOfSentenceTextIndex = find_end_of_sentence(currentSegmentText)\n",
        "        endOfSentenceText = currentSegmentText[0:endOfSentenceTextIndex + 1]\n",
        "\n",
        "        # If the segment is a complete sentence, then create a new segment and append it to the newSegmentList.\n",
        "        completeSentence = accumulatedSentenceText + endOfSentenceText\n",
        "        completeSentenceEnd = currentSegment.get(\"end\")\n",
        "\n",
        "        # If the segment is a complete sentence, then create a new segment and append it to the newSegmentList.\n",
        "        # The new segment will have the same start time as the first segment in the sentence.\n",
        "        # The new segment will have the same end time as the last segment in the sentence.\n",
        "        # The new segment will have the text of the sentence.\n",
        "        newSegment = {\"text\": completeSentence, \"start\": accumulatedSentenceStart, \"end\": completeSentenceEnd}\n",
        "        newSegmentList.append(newSegment)\n",
        "\n",
        "        # Is there remaining text in the current segment?\n",
        "        # If so, then call transcribe with the remaining text.\n",
        "        # If not, then call transcribe with the next segment.\n",
        "        if endOfSentenceTextIndex + 1 < len(currentSegmentText):\n",
        "            remainingText = currentSegmentText[endOfSentenceTextIndex + 2:]\n",
        "            transcribe(thisStartTimeStamp, remainingText, segmentIndex + 1, segmentsArray)\n",
        "        else:\n",
        "            transcribe(None, None, segmentIndex + 1, segmentsArray)\n"
      ],
      "metadata": {
        "id": "BMCVnL4v1YBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Upload any video files you want transcribed in the \"WhisperVideo\" folder in your Google Drive."
      ],
      "metadata": {
        "id": "7fr8tBQy5Tvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Extract audio from the video files and create a transcription"
      ],
      "metadata": {
        "id": "nCef9V2i392e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# an empty dictionary\n",
        "newSegmentList = []\n",
        "# Load all the audio file paths in a Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# Get the list of video files from the WhisperVideo folder\n",
        "video_files = os.listdir(\"/content/drive/MyDrive/WhisperVideo/\")\n",
        "\n",
        "# Loop through the video files and transcribe them\n",
        "for video_file in video_files:\n",
        "\n",
        "  # Skip the file if it is not a video format\n",
        "  if not video_file.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\")):\n",
        "    continue\n",
        "\n",
        "  # Extract the audio from the video file using librosa\n",
        "  video_path = \"/content/drive/MyDrive/WhisperVideo/\" + video_file\n",
        "  audio_path = \"/content/drive/MyDrive/WhisperVideo/AudioFiles/\" + video_file[:-4] + \".wav\" # Replace the video extension with .wav\n",
        "\n",
        "  y, sr = librosa.load(video_path, sr=16000) # Load the audio with 16 kHz sampling rate\n",
        "  sf.write(audio_path, y, sr) # Save the audio as a wav file\n",
        "\n",
        "  # Transcribe the audio file using Whisper\n",
        "  result = model.transcribe(audio_path)\n",
        "\n",
        "  print(json.dumps(result, indent = 2, ensure_ascii = False))\n",
        "\n",
        "  segments = result.get(\"segments\")\n",
        "  print(json.dumps(segments, indent = 2, ensure_ascii = False))\n",
        "  if segments is None:\n",
        "      print(\"No segments found\")\n",
        "      exit(1)\n",
        "\n",
        "  transcribe(None, None, 0, segments)\n",
        "  \n",
        "\n",
        "  print(json.dumps(newSegmentList, indent = 2, ensure_ascii = False))\n",
        "\n",
        "  text = result[\"text\"].strip()\n",
        "  text = text.replace(\". \", \".\\n\\n\")\n",
        "\n",
        "  # Save the transcription as a text file in Google Docs\n",
        "  text_file = video_file[:-4] + \".txt\" # Replace the video extension with .txt\n",
        "  text_path = \"/content/drive/MyDrive/WhisperVideo/TextFiles/\" + text_file\n",
        "  with open(text_path, \"w\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  json_file = video_file[:-4] + \".json\"\n",
        "  json_path = \"/content/drive/MyDrive/WhisperVideo/JsonFiles/\" + json_file\n",
        "  with open(json_path, \"w\") as f:\n",
        "    f.write(json.dumps(newSegmentList, indent = 2, ensure_ascii = False))\n",
        "    \n",
        "  # Move the video file to the ProcessedVideo folder\n",
        "  processed_path = \"/content/drive/MyDrive/WhisperVideo/ProcessedVideo/\" + video_file\n",
        "  os.rename(video_path, processed_path)\n",
        "\n",
        "  # Print a message to indicate the progress\n",
        "  print(\"Processed {video_file} and saved the transcription as {text_file}\")"
      ],
      "metadata": {
        "id": "D_rB5M99nmhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5760d76-4062-49a2-e5e2-fc677304712d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"text\": \" So it seems like I need to record more audio for Whisper to be able to learn my speech patterns and for Whisper to correctly punctuate what I'm saying. So in order to provide some more verbiage here I'm just gonna babble for a little bit. I hope you're listening Whisper and that based on what I'm saying you'll be able to punctuate the transcription accordingly. Thank you and may your feet go with you.\",\n",
            "  \"segments\": [\n",
            "    {\n",
            "      \"id\": 0,\n",
            "      \"seek\": 0,\n",
            "      \"start\": 0.0,\n",
            "      \"end\": 6.32,\n",
            "      \"text\": \" So it seems like I need to record more audio for Whisper to be able to learn\",\n",
            "      \"tokens\": [\n",
            "        50363,\n",
            "        1406,\n",
            "        340,\n",
            "        2331,\n",
            "        588,\n",
            "        314,\n",
            "        761,\n",
            "        284,\n",
            "        1700,\n",
            "        517,\n",
            "        6597,\n",
            "        329,\n",
            "        28424,\n",
            "        525,\n",
            "        284,\n",
            "        307,\n",
            "        1498,\n",
            "        284,\n",
            "        2193,\n",
            "        50679\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1390289867625517,\n",
            "      \"compression_ratio\": 1.6358974358974359,\n",
            "      \"no_speech_prob\": 0.5587785840034485\n",
            "    },\n",
            "    {\n",
            "      \"id\": 1,\n",
            "      \"seek\": 0,\n",
            "      \"start\": 6.32,\n",
            "      \"end\": 14.48,\n",
            "      \"text\": \" my speech patterns and for Whisper to correctly punctuate what I'm saying. So in\",\n",
            "      \"tokens\": [\n",
            "        50679,\n",
            "        616,\n",
            "        4046,\n",
            "        7572,\n",
            "        290,\n",
            "        329,\n",
            "        28424,\n",
            "        525,\n",
            "        284,\n",
            "        9380,\n",
            "        21025,\n",
            "        4985,\n",
            "        644,\n",
            "        314,\n",
            "        1101,\n",
            "        2282,\n",
            "        13,\n",
            "        1406,\n",
            "        287,\n",
            "        51087\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1390289867625517,\n",
            "      \"compression_ratio\": 1.6358974358974359,\n",
            "      \"no_speech_prob\": 0.5587785840034485\n",
            "    },\n",
            "    {\n",
            "      \"id\": 2,\n",
            "      \"seek\": 0,\n",
            "      \"start\": 14.48,\n",
            "      \"end\": 19.32,\n",
            "      \"text\": \" order to provide some more verbiage here I'm just gonna babble for a little bit.\",\n",
            "      \"tokens\": [\n",
            "        51087,\n",
            "        1502,\n",
            "        284,\n",
            "        2148,\n",
            "        617,\n",
            "        517,\n",
            "        3326,\n",
            "        8482,\n",
            "        496,\n",
            "        994,\n",
            "        314,\n",
            "        1101,\n",
            "        655,\n",
            "        8066,\n",
            "        9289,\n",
            "        903,\n",
            "        329,\n",
            "        257,\n",
            "        1310,\n",
            "        1643,\n",
            "        13,\n",
            "        51329\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1390289867625517,\n",
            "      \"compression_ratio\": 1.6358974358974359,\n",
            "      \"no_speech_prob\": 0.5587785840034485\n",
            "    },\n",
            "    {\n",
            "      \"id\": 3,\n",
            "      \"seek\": 0,\n",
            "      \"start\": 19.32,\n",
            "      \"end\": 24.96,\n",
            "      \"text\": \" I hope you're listening Whisper and that based on what I'm saying you'll be able\",\n",
            "      \"tokens\": [\n",
            "        51329,\n",
            "        314,\n",
            "        2911,\n",
            "        345,\n",
            "        821,\n",
            "        8680,\n",
            "        28424,\n",
            "        525,\n",
            "        290,\n",
            "        326,\n",
            "        1912,\n",
            "        319,\n",
            "        644,\n",
            "        314,\n",
            "        1101,\n",
            "        2282,\n",
            "        345,\n",
            "        1183,\n",
            "        307,\n",
            "        1498,\n",
            "        51611\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1390289867625517,\n",
            "      \"compression_ratio\": 1.6358974358974359,\n",
            "      \"no_speech_prob\": 0.5587785840034485\n",
            "    },\n",
            "    {\n",
            "      \"id\": 4,\n",
            "      \"seek\": 2496,\n",
            "      \"start\": 24.96,\n",
            "      \"end\": 31.6,\n",
            "      \"text\": \" to punctuate the transcription accordingly. Thank you and may your feet\",\n",
            "      \"tokens\": [\n",
            "        50363,\n",
            "        284,\n",
            "        21025,\n",
            "        4985,\n",
            "        262,\n",
            "        26955,\n",
            "        16062,\n",
            "        13,\n",
            "        6952,\n",
            "        345,\n",
            "        290,\n",
            "        743,\n",
            "        534,\n",
            "        3625,\n",
            "        50695\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1997156576676802,\n",
            "      \"compression_ratio\": 1.0769230769230769,\n",
            "      \"no_speech_prob\": 0.015120955184102058\n",
            "    },\n",
            "    {\n",
            "      \"id\": 5,\n",
            "      \"seek\": 2496,\n",
            "      \"start\": 31.6,\n",
            "      \"end\": 34.32,\n",
            "      \"text\": \" go with you.\",\n",
            "      \"tokens\": [\n",
            "        50695,\n",
            "        467,\n",
            "        351,\n",
            "        345,\n",
            "        13,\n",
            "        50831\n",
            "      ],\n",
            "      \"temperature\": 0.0,\n",
            "      \"avg_logprob\": -0.1997156576676802,\n",
            "      \"compression_ratio\": 1.0769230769230769,\n",
            "      \"no_speech_prob\": 0.015120955184102058\n",
            "    }\n",
            "  ],\n",
            "  \"language\": \"en\"\n",
            "}\n",
            "[\n",
            "  {\n",
            "    \"id\": 0,\n",
            "    \"seek\": 0,\n",
            "    \"start\": 0.0,\n",
            "    \"end\": 6.32,\n",
            "    \"text\": \" So it seems like I need to record more audio for Whisper to be able to learn\",\n",
            "    \"tokens\": [\n",
            "      50363,\n",
            "      1406,\n",
            "      340,\n",
            "      2331,\n",
            "      588,\n",
            "      314,\n",
            "      761,\n",
            "      284,\n",
            "      1700,\n",
            "      517,\n",
            "      6597,\n",
            "      329,\n",
            "      28424,\n",
            "      525,\n",
            "      284,\n",
            "      307,\n",
            "      1498,\n",
            "      284,\n",
            "      2193,\n",
            "      50679\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1390289867625517,\n",
            "    \"compression_ratio\": 1.6358974358974359,\n",
            "    \"no_speech_prob\": 0.5587785840034485\n",
            "  },\n",
            "  {\n",
            "    \"id\": 1,\n",
            "    \"seek\": 0,\n",
            "    \"start\": 6.32,\n",
            "    \"end\": 14.48,\n",
            "    \"text\": \" my speech patterns and for Whisper to correctly punctuate what I'm saying. So in\",\n",
            "    \"tokens\": [\n",
            "      50679,\n",
            "      616,\n",
            "      4046,\n",
            "      7572,\n",
            "      290,\n",
            "      329,\n",
            "      28424,\n",
            "      525,\n",
            "      284,\n",
            "      9380,\n",
            "      21025,\n",
            "      4985,\n",
            "      644,\n",
            "      314,\n",
            "      1101,\n",
            "      2282,\n",
            "      13,\n",
            "      1406,\n",
            "      287,\n",
            "      51087\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1390289867625517,\n",
            "    \"compression_ratio\": 1.6358974358974359,\n",
            "    \"no_speech_prob\": 0.5587785840034485\n",
            "  },\n",
            "  {\n",
            "    \"id\": 2,\n",
            "    \"seek\": 0,\n",
            "    \"start\": 14.48,\n",
            "    \"end\": 19.32,\n",
            "    \"text\": \" order to provide some more verbiage here I'm just gonna babble for a little bit.\",\n",
            "    \"tokens\": [\n",
            "      51087,\n",
            "      1502,\n",
            "      284,\n",
            "      2148,\n",
            "      617,\n",
            "      517,\n",
            "      3326,\n",
            "      8482,\n",
            "      496,\n",
            "      994,\n",
            "      314,\n",
            "      1101,\n",
            "      655,\n",
            "      8066,\n",
            "      9289,\n",
            "      903,\n",
            "      329,\n",
            "      257,\n",
            "      1310,\n",
            "      1643,\n",
            "      13,\n",
            "      51329\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1390289867625517,\n",
            "    \"compression_ratio\": 1.6358974358974359,\n",
            "    \"no_speech_prob\": 0.5587785840034485\n",
            "  },\n",
            "  {\n",
            "    \"id\": 3,\n",
            "    \"seek\": 0,\n",
            "    \"start\": 19.32,\n",
            "    \"end\": 24.96,\n",
            "    \"text\": \" I hope you're listening Whisper and that based on what I'm saying you'll be able\",\n",
            "    \"tokens\": [\n",
            "      51329,\n",
            "      314,\n",
            "      2911,\n",
            "      345,\n",
            "      821,\n",
            "      8680,\n",
            "      28424,\n",
            "      525,\n",
            "      290,\n",
            "      326,\n",
            "      1912,\n",
            "      319,\n",
            "      644,\n",
            "      314,\n",
            "      1101,\n",
            "      2282,\n",
            "      345,\n",
            "      1183,\n",
            "      307,\n",
            "      1498,\n",
            "      51611\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1390289867625517,\n",
            "    \"compression_ratio\": 1.6358974358974359,\n",
            "    \"no_speech_prob\": 0.5587785840034485\n",
            "  },\n",
            "  {\n",
            "    \"id\": 4,\n",
            "    \"seek\": 2496,\n",
            "    \"start\": 24.96,\n",
            "    \"end\": 31.6,\n",
            "    \"text\": \" to punctuate the transcription accordingly. Thank you and may your feet\",\n",
            "    \"tokens\": [\n",
            "      50363,\n",
            "      284,\n",
            "      21025,\n",
            "      4985,\n",
            "      262,\n",
            "      26955,\n",
            "      16062,\n",
            "      13,\n",
            "      6952,\n",
            "      345,\n",
            "      290,\n",
            "      743,\n",
            "      534,\n",
            "      3625,\n",
            "      50695\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1997156576676802,\n",
            "    \"compression_ratio\": 1.0769230769230769,\n",
            "    \"no_speech_prob\": 0.015120955184102058\n",
            "  },\n",
            "  {\n",
            "    \"id\": 5,\n",
            "    \"seek\": 2496,\n",
            "    \"start\": 31.6,\n",
            "    \"end\": 34.32,\n",
            "    \"text\": \" go with you.\",\n",
            "    \"tokens\": [\n",
            "      50695,\n",
            "      467,\n",
            "      351,\n",
            "      345,\n",
            "      13,\n",
            "      50831\n",
            "    ],\n",
            "    \"temperature\": 0.0,\n",
            "    \"avg_logprob\": -0.1997156576676802,\n",
            "    \"compression_ratio\": 1.0769230769230769,\n",
            "    \"no_speech_prob\": 0.015120955184102058\n",
            "  }\n",
            "]\n",
            " So it seems like I need to record more audio for Whisper to be able to learn\n",
            " my speech patterns and for Whisper to correctly punctuate what I'm saying. So in\n",
            " my speech patterns and for Whisper to correctly punctuate what I'm saying. So in\n",
            " order to provide some more verbiage here I'm just gonna babble for a little bit.\n",
            " order to provide some more verbiage here I'm just gonna babble for a little bit.\n",
            " I hope you're listening Whisper and that based on what I'm saying you'll be able\n",
            " to punctuate the transcription accordingly. Thank you and may your feet\n",
            " to punctuate the transcription accordingly. Thank you and may your feet\n",
            " go with you.\n",
            " go with you.\n",
            "[\n",
            "  {\n",
            "    \"text\": \" So it seems like I need to record more audio for Whisper to be able to learn my speech patterns and for Whisper to correctly punctuate what I'm saying.\",\n",
            "    \"start\": null,\n",
            "    \"end\": 14.48\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"So in order to provide some more verbiage here I'm just gonna babble for a little bit.\",\n",
            "    \"start\": 6.32,\n",
            "    \"end\": 19.32\n",
            "  },\n",
            "  {\n",
            "    \"text\": \" I hope you're listening Whisper and that based on what I'm saying you'll be able to punctuate the transcription accordingly.\",\n",
            "    \"start\": null,\n",
            "    \"end\": 31.6\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"Thank you and may your feet go with you.\",\n",
            "    \"start\": 24.96,\n",
            "    \"end\": 34.32\n",
            "  }\n",
            "]\n",
            "Processed {video_file} and saved the transcription as {text_file}\n"
          ]
        }
      ]
    }
  ]
}